# -*- coding: utf-8 -*-
"""Ml_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rwo3S0IUstl1NrfPZm6RhMu-BeCX_dlW
"""

import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

df=pd.read_csv('/content/updated_pakwheels.csv')

df = df.drop(columns=["Color" , "Last Updated" , "URL" , "Ad No" ,  "Name" , "Location" , "Registered City" , "Features","Mileage", "Engine Type"])

df.columns

df.isnull().sum()

le = LabelEncoder()
# Using .fit_transform function to fit label
# encoder and return encoded label
label = le.fit_transform(df['Assembly'])
 
# printing label
label

# removing the column 'Purchased' from df
# as it is of no use now.
df.drop("Assembly", axis=1, inplace=True)
 
# Appending the array to our dataFrame
# with column name 'Purchased'
df["Assembly"] = label
 
# printing Dataframe
df

df.info()

plt.figure(figsize=(20,20)) 
sns.heatmap(df.corr(), annot=True, fmt='.3f')

data_plot = df

sns.lineplot(x = "Price", y = "Model Year", data=data_plot)
plt.show()

data_plot = df

sns.lineplot(x = "Price", y = "Engine Capacity", data=data_plot)
plt.show()

data_plot = df

sns.lineplot(x = "Price", y = "Transmission", data=data_plot)
plt.show()

data_plot = df

sns.lineplot(x = "Price", y = "Body Type", data=data_plot)
plt.show()

data_plot = df

sns.lineplot(x = "Price", y = "Assembly", data=data_plot)
plt.show()

#indep variables
X = df.iloc[:, :-1].values 
#dep variables
Y = df.iloc[:,-1].values 
print('Features: ',X)
print('Label: ',Y)


#spliting
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(df[['Model Year',  'Engine Capacity',
       'Transmission', 'Assembly', 'Body Type',]],df.Price, test_size = 0.20, random_state = 0)
#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
print('X-Train: ',X_train)
print('X-Test:',X_test)

# with sklearn
from sklearn import linear_model
regr = linear_model.LinearRegression()
regr.fit(X_train, Y_train)
print('Intercept: \n', regr.intercept_)
print('Coefficients: \n', regr.coef_)
predictions = regr.predict(X_test)

from sklearn.metrics import mean_squared_error, mean_absolute_error
# model evaluation
mse=mean_squared_error(Y_test, predictions)
print('mean_squared_error : ', mse)
mae=mean_absolute_error(Y_test, predictions)
print('mean_absolute_error : ', mae)

from scipy.sparse.linalg.isolve.lsqr import sqrt
rmse=sqrt(mse)
print("root_mean_squared_error is",rmse)

r2=r2_score(Y_test,predictions)
print("coefficent of determination is ",r2)

df.to_csv(r'export_dataframe.csv', index=False, header=True)

#df1=df.loc[0:5000,:]
df1=df.sample(frac = 0.25)

plt.figure(figsize=(20,20)) 
sns.heatmap(df1.corr(), annot=True, fmt='.3f')

#indep variables
X = df1.iloc[:, :-1].values 
#dep variables
Y = df1.iloc[:,-1].values 
print('Features: ',X)
print('Label: ',Y)


#spliting
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(df1[['Model Year',  'Engine Capacity',
       'Transmission', 'Assembly', 'Body Type',]],df1.Price, test_size = 0.20, random_state = 0)
#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
print('X-Train: ',X_train)
print('X-Test:',X_test)

# with sklearn
from sklearn import linear_model
regr = linear_model.LinearRegression()
regr.fit(X_train, Y_train)
print('Intercept: \n', regr.intercept_)
print('Coefficients: \n', regr.coef_)
predictions = regr.predict(X_test)

from sklearn.metrics import mean_squared_error, mean_absolute_error
# model evaluation
mse=mean_squared_error(Y_test, predictions)
print('mean_squared_error : ', mse)
mae=mean_absolute_error(Y_test, predictions)
print('mean_absolute_error : ', mae)

from scipy.sparse.linalg.isolve.lsqr import sqrt
rmse=sqrt(mse)
print("root_mean_squared_error is",rmse)

r2=r2_score(Y_test,predictions)
print("coefficent of determination is ",r2)

#Using KNeighborsClassifier 
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
knn.fit(X_train, Y_train)
model=knn.fit(X_train, Y_train)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_test, model.predict(X_test))

TN = cm[0][0]
TP = cm[1][1]
FN = cm[1][0]
FP = cm[0][1]

#print(cm)
print('Model[{}] Testing Accuracy = "{}!"'.format(model,  (TP + TN) / (TP + TN + FN + FP)))
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt=".3f", linewidths=.5, square = True, cmap = 'Blues_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Model[{}] Testing Accuracy = "{}!'.format(model,  (TP + TN) / (TP + TN + FN + FP))
plt.title(all_sample_title, size = 15);
print()# Print a new line

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
import yellowbrick.classifier
from yellowbrick.classifier import ClassificationReport


print('Model ',model)
#Check precision, recall, f1-score
print( classification_report(Y_test, model.predict(X_test)) )
# Instantiate the classification model and visualizer
visualizer = ClassificationReport(model, classes=['Yes','No'])
visualizer.fit(X_train, Y_train) # Fit the training data to the visualizer
visualizer.score(X_test, Y_test) # Evaluate the model on the test data
g = visualizer.poof() # Draw/show/poof the data
#Another way to get the models accuracy on the test data
print('Accuray Score on Test Data: ', accuracy_score(Y_test, model.predict(X_test)))
print()#Print a new line

from sklearn import metrics

print('Model',model)
y_pred = model.predict(X_test)
dff=pd.DataFrame({'Actual Value':Y_test, 'Predicted Value':y_pred})
print(dff)
print()
cm = metrics.confusion_matrix(Y_test, y_pred)
print('Confusion Matrix\n',cm)

from sklearn import metrics
print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))
r2=r2_score(Y_test, y_pred)
print("coefficent of determination is ",r2)